# LXRT - Raport Rozwojowy dla Lidera Projektu
**Data:** 2026-01-21  
**殴r贸do:** Integracja z frameworkiem Stagehand (browser automation)  
**Autor:** AI Assistant (Antigravity)

---

## Podsumowanie Wykonawcze

Podczas integracji LXRT z Stagehand zidentyfikowano **12 konkretnych obszar贸w** wymagajcych poprawy. Poni偶ej przedstawiono szczeg贸ow list z uzasadnieniami i przykadami z rzeczywistego kodu.

---

## PRIORYTET KRYTYCZNY 

### 1. Brak funkcji `countTokens()`

**Problem:**  
Nie ma mo偶liwoci sprawdzenia ile token贸w zajmuje tekst przed wysaniem do modelu. Prowadzi to do nieprzewidywalnych obci lub bd贸w "context overflow".

**Uzasadnienie:**  
Podczas ekstrakcji treci ze strony `stallman.org` otrzymalimy 11,894 znak贸w. Nie wiedzc ile to token贸w, musielimy arbitralnie obci do 1500 znak贸w, tracc potencjalnie wa偶ne dane.

**Jak to obeszlimy:**
```typescript
// WORKAROUND: Rczne obcinanie bez wiedzy o tokenach
const text = sectionContent.text.slice(0, 1500); // Arbitralna warto!

// Rczne ostrze偶enie
if (sectionContent.charCount > 1500) {
    console.warn(`锔 WARNING: Input truncated from ${sectionContent.charCount} to 1500 chars`);
}
```

**Proponowane API:**
```typescript
const tokenCount = await provider.countTokens(text);
const contextWindow = provider.getContextWindow(); // np. 4096

if (tokenCount > contextWindow - 512) { // -512 na odpowied藕
    text = text.slice(0, estimateCharsForTokens(contextWindow - 512));
}
```

**Estymowany nakad:** 2-3 dni

---

### 2. Wolny inference na CPU/WASM

**Problem:**  
Generowanie 64 token贸w trwa ~17 sekund na CPU. Dla responsywnych aplikacji to za wolno.

**Uzasadnienie:**  
Nasz cel byo <10s. Nawet po agresywnej optymalizacji (zmniejszenie modelu, token贸w, inputu) nie udao si zej poni偶ej 17s.

**Dane benchmarkowe:**
| Konfiguracja | Czas |
|--------------|------|
| Phi-3 (3.8B), 512 token贸w, 4000 znak贸w | ~5 minut |
| Qwen 0.5B, 128 token贸w, 1500 znak贸w | 31.32s |
| Qwen 0.5B, 64 tokeny, 500 znak贸w | **17.56s** |

**Jak to obeszlimy:**
```typescript
// Zmniejszenie wszystkiego co mo偶liwe
{ maxTokens: 64 }  // zamiast 512
sectionContent.text.slice(0, 500)  // zamiast 4000
model: 'Xenova/Qwen1.5-0.5B-Chat'  // zamiast Phi-3
```

**Propozycja rozwizania:**
1. **WebGPU backend** - 10-50x przyspieszenie (priorytet!)
2. **SIMD optimizations** dla WASM
3. **Speculative decoding** dla szybszego generowania

**Estymowany nakad:** 2-4 tygodnie

---

### 3. Brak `getContextWindow()`

**Problem:**  
Nie ma sposobu na programowe sprawdzenie rozmiaru okna kontekstowego modelu.

**Uzasadnienie:**  
Ka偶dy model ma inny limit (Qwen: 4096, Phi-3: 4096, Llama: 8192). Bez tej informacji nie mo偶na dynamicznie dostosowa inputu.

**Jak to obeszlimy:**
```typescript
// WORKAROUND: Hardkodowany limit
const MAX_INPUT_CHARS = 1500; // Zgadujemy 偶e to bezpieczne
```

**Proponowane API:**
```typescript
const model = await provider.getModelInfo();
console.log(model.contextWindow); // 4096
console.log(model.maxTokens); // 2048
```

**Estymowany nakad:** 1-2 dni

---

## PRIORYTET WYSOKI 

### 4. Brak Abort/Cancel dla inference

**Problem:**  
Nie mo偶na przerwa trwajcego inference. U偶ytkownik musi czeka nawet jeli chce anulowa.

**Uzasadnienie:**  
W aplikacji Stagehand, jeli u偶ytkownik zamknie przegldark w trakcie generowania, proces nadal dziaa w tle.

**Jak to obeszlimy:**
```typescript
// Brak obejcia - musielimy czeka lub zabi proces
process.exit(0); // Brutalne rozwizanie
```

**Proponowane API:**
```typescript
const controller = new AbortController();
const response = await provider.chat(messages, { 
    signal: controller.signal 
});

// Timeout po 10s
setTimeout(() => controller.abort(), 10000);
```

**Estymowany nakad:** 3-5 dni

---

### 5. Brak JSON Mode

**Problem:**  
Nie ma gwarancji 偶e model zwr贸ci poprawny JSON. Trzeba parsowa regex i obsugiwa bdy.

**Uzasadnienie:**  
Stagehand wymaga strukturalnych odpowiedzi (schematy Zod). Mae modele (0.5B) czsto generuj niepoprawny JSON.

**Jak to obeszlimy:**
```typescript
// WORKAROUND: Regex parsing z fallbackiem
try {
    const jsonMatches = response.content.match(/\{[\s\S]*?\}/g);
    if (jsonMatches) {
        for (const match of jsonMatches) {
            try {
                const parsed = JSON.parse(match);
                if (parsed.talks && parsed.talks.length > 0) {
                    return parsed;
                }
            } catch (e) { /* ignore */ }
        }
    }
} catch (parseError) {
    console.log("锔 Could not parse as JSON");
}
```

**Proponowane API:**
```typescript
const response = await provider.chat(messages, {
    responseFormat: { 
        type: "json_object",
        schema: z.object({ talks: z.array(...) }) // Zod schema
    }
});
// Gwarantowany poprawny JSON lub error
```

**Estymowany nakad:** 1 tydzie

---

### 6. Brak Function Calling

**Problem:**  
Nie ma natywnego wsparcia dla tool/function calling, kt贸re jest standardem w nowoczesnych LLM API.

**Uzasadnienie:**  
Stagehand u偶ywa function calling do sterowania przegldark (click, type, extract). Musielimy to emulowa w prompcie.

**Jak to obeszlimy:**
```typescript
// WORKAROUND: Instrukcje w prompcie zamiast narzdzi
const prompt = `Extract first event: ${text}
Format: Date - Location - Title`;
// Zamiast:
// tools: [{ name: "extract_event", parameters: {...} }]
```

**Proponowane API:**
```typescript
const response = await provider.chat(messages, {
    tools: [{
        type: "function",
        function: {
            name: "extract_event",
            description: "Extracts event from text",
            parameters: {
                type: "object",
                properties: {
                    date: { type: "string" },
                    location: { type: "string" }
                }
            }
        }
    }]
});

if (response.tool_calls) {
    const call = response.tool_calls[0];
    console.log(call.function.arguments); // { date: "Jan 23", location: "Atlanta" }
}
```

**Estymowany nakad:** 2 tygodnie

---

## PRIORYTET REDNI 

### 7. Problemy z Path Aliases w Build

**Problem:**  
Po kompilacji TypeScript, aliasy (`@domain/*`) nie s rozwizywane, powodujc bdy importu.

**Uzasadnienie:**  
Przy pierwszym uruchomieniu przykadu Stagehand otrzymalimy bd:
```
Cannot find module '@domain/errors'
```

**Jak to naprawilimy:**
```json
// package.json - musielimy doda tsc-alias
"scripts": {
    "build": "tsc && tsc-alias"  // Dodatkowy krok!
}
```

**Propozycja:**
- Rozwa偶y u偶ycie `tsup` lub `esbuild` zamiast raw `tsc`
- Lub doczy `tsc-alias` jako dependency i zautomatyzowa

**Estymowany nakad:** 0.5 dnia

---

### 8. Konflikt wersji ONNX Runtime

**Problem:**  
LXRT wymaga `onnxruntime-node@1.23.0`, ale `@huggingface/transformers` wymaga `1.21.0`.

**Uzasadnienie:**  
Przy instalacji otrzymalimy ostrze偶enia o konflikcie, a p贸藕niej bdy adowania modelu:
```
Protobuf parsing failed
```

**Jak to naprawilimy:**
```bash
# Usunicie nadmiarowej zale偶noci
npm uninstall onnxruntime-node
# U偶ycie wersji z @huggingface/transformers
```

**Propozycja:**
- Usun bezporedni zale偶no `onnxruntime-node` z package.json
- Polega na wersji dostarczanej przez `@huggingface/transformers`

**Estymowany nakad:** 0.5 dnia

---

### 9. Brak typ贸w dla Event Payloads

**Problem:**  
Eventy `progress` i `ready` nie maj wyeksportowanych typ贸w TypeScript.

**Uzasadnienie:**  
IDE nie podpowiada dostpnych p贸l, co utrudnia development.

**Jak to obeszlimy:**
```typescript
// Zgadywanie struktury na podstawie log贸w
provider.on('progress', (data) => {
    const percent = data.progress?.toFixed(1) ?? '?';  // Nie wiemy czy istnieje!
    const file = data.file ?? 'unknown';
    const status = data.status ?? 'loading';
    // ...
});
```

**Proponowane typy:**
```typescript
// Eksportowa z biblioteki:
export interface ProgressEvent {
    modality: 'llm' | 'embeddings' | 'vision';
    model: string;
    file: string;
    progress: number; // 0-100
    loaded: number;   // bytes
    total: number;    // bytes
    status: 'downloading' | 'loading' | 'ready';
}

export interface ReadyEvent {
    modality: 'llm' | 'embeddings' | 'vision';
    model: string;
}
```

**Estymowany nakad:** 0.5 dnia

---

### 10. Dokumentacja Streaming API

**Problem:**  
Brak dokumentacji jak u偶ywa `provider.stream()`.

**Uzasadnienie:**  
Musielimy szuka w kodzie 藕r贸dowym (`grep_search stream`) aby znale藕 偶e ta funkcja istnieje.

**Jak to odkrylimy:**
```bash
# Szukanie w 藕r贸dach
grep -r "stream" src/app/AIProvider.ts
# Znale藕limy: async *stream(
```

**Propozycja:**
Doda do dokumentacji:
```markdown
## Streaming Responses

```typescript
for await (const token of provider.stream(messages, options)) {
    process.stdout.write(token);
}
```
```

**Estymowany nakad:** 0.5 dnia

---

### 11. Brak przykad贸w integracji

**Problem:**  
Brak oficjalnych przykad贸w integracji z popularnymi frameworkami.

**Uzasadnienie:**  
Musielimy od zera pisa `LxrtLLMProvider` dla Stagehand, zgadujc jak mapowa API.

**Jak to zrobilimy:**
```typescript
// Napisalimy wasny adapter (109 linii kodu)
export class LxrtLLMProvider implements LLMClient {
    async createChatCompletion(options) {
        // Mapowanie Stagehand -> LXRT
        const messages = options.messages.map(m => ({
            role: m.role,
            content: typeof m.content === 'string' ? m.content : '...'
        }));
        // ...
    }
}
```

**Propozycja:**
Stworzy oficjalne adaptery:
- `@lxrt/stagehand` - adapter dla Stagehand
- `@lxrt/langchain` - adapter dla LangChain.js
- `@lxrt/vercel-ai` - adapter dla Vercel AI SDK

**Estymowany nakad:** 1 tydzie per adapter

---

### 12. Brak CLI do zarzdzania modelami

**Problem:**  
Nie ma sposobu na pre-download modeli przed uruchomieniem aplikacji.

**Uzasadnienie:**  
Pierwszy start aplikacji trwa dugo (pobieranie modelu). W produkcji chcemy mie modele ju偶 pobrane.

**Jak to obeszlimy:**
```typescript
// Model pobiera si przy pierwszym warmup()
await provider.warmup('llm'); // Tutaj dopiero ciga ~1GB
```

**Proponowane CLI:**
```bash
# Pre-download modeli
npx lxrt pull Xenova/Qwen1.5-0.5B-Chat --dtype q4

# Lista pobranych modeli
npx lxrt list

# Usu model z cache
npx lxrt remove Xenova/Phi-3-mini-4k-instruct
```

**Estymowany nakad:** 1 tydzie

---

### 13. Brak Registry i Type-Safety dla modeli

**Problem:**  
Wszystkie konfiguracje modeli (`LLMConfig`, `STTConfig`) u偶ywaj typu `string` dla pola `model`. Brak weryfikacji czy model istnieje oraz brak autouzupeniania w IDE.

**Uzasadnienie:**  
Programista musi zna dokadne ID modelu z Hugging Face (np. `Xenova/whisper-tiny`). Liter贸wka powoduje bd dopiero w runtime (przy pr贸bie pobrania).

**Jak to obeszlimy:**  
Rczne wpisywanie string贸w bez walidacji.

**Proponowane rozwizanie (Model Registry):**
Implementacja podejcia "Registry + Type-Safety":
- **Registry:** Centralny plik `src/core/ModelRegistry.ts` z definicjami przetestowanych modeli.
- **Typy:** `type SupportedLLM = keyof typeof MODEL_REGISTRY.llm`.
- **Hybrid types:** `model: SupportedLLM | (string & {})` - zapewnia autouzupenianie dla znanych modeli, zachowujc mo偶liwo wpisania dowolnego stringa.

**Estymowany nakad:** 2-3 dni

---

## Podsumowanie Priorytet贸w

| # | Zadanie | Priorytet | Nakad | Wpyw |
|---|---------|-----------|--------|-------|
| 1 | `countTokens()` |  Krytyczny | 2-3 dni | Wysoki |
| 2 | WebGPU backend |  Krytyczny | 2-4 tyg | Bardzo wysoki |
| 3 | `getContextWindow()` |  Krytyczny | 1-2 dni | Wysoki |
| 4 | Abort/Cancel |  Wysoki | 3-5 dni | redni |
| 5 | JSON Mode |  Wysoki | 1 tydzie | Wysoki |
| 6 | Function Calling |  Wysoki | 2 tygodnie | Wysoki |
| 7 | Fix path aliases |  redni | 0.5 dnia | Niski |
| 8 | Fix ONNX conflict |  redni | 0.5 dnia | Niski |
| 9 | Typy event贸w |  redni | 0.5 dnia | Niski |
| 10 | Docs streaming |  redni | 0.5 dnia | Niski |
| 11 | Adaptery integracji |  redni | 3 tygodnie | redni |
| 12 | CLI zarzdzania |  redni | 1 tydzie | redni |
| 13 | Model Registry & Types |  redni | 2-3 dni | redni |

**Sugerowana kolejno na nastpny cykl:**
1. Fix ONNX conflict + path aliases (szybkie wygrane)
2. `countTokens()` + `getContextWindow()` (krytyczne dla UX)
3. Abort/Cancel + typy event贸w
4. Dokumentacja streaming + przykady
5. WebGPU (dugoterminowy, ale game-changer)

---

## Zaczniki

### A. Kod adaptera Stagehand
Lokalizacja: `/home/pyroxar/Pulpit/lxrt/examples/stagehand/src/LxrtLLMProvider.ts`

### B. Zoptymalizowany przykad
Lokalizacja: `/home/pyroxar/Pulpit/lxrt/examples/stagehand/src/index.ts`

### C. Benchmark wynik贸w
- Model: Qwen1.5-0.5B-Chat (q4)
- Czas: 17.56s dla 64 token贸w
- Platform: CPU/WASM (Linux x64)
