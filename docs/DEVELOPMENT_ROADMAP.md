# LXRT - Development Roadmap

**Ostatnia aktualizacja:** 2026-01-29  
**Status:** Aktywny rozwÃ³j

---

## ðŸ“‹ DO ZROBIENIA (TODO)

### ðŸŸ¡ Wysokie

#### Abort/Cancel dla Inference
**Problem:** Nie moÅ¼na przerwaÄ‡ trwajÄ…cego inference w peÅ‚ni (czÄ™Å›ciowo zaimplementowane w LLMModel).

**Status:** CzÄ™Å›ciowo done â€” `AbortSignal` w `ChatOptions`, brakuje peÅ‚nej propagacji do pipeline.

**NakÅ‚ad:** 3-5 dni

---

#### JSON Mode
**Problem:** Brak gwarancji Å¼e model zwrÃ³ci poprawny JSON.

**Proponowane API:**
```typescript
const response = await provider.chat(messages, {
    responseFormat: { 
        type: "json_object",
        schema: z.object({ talks: z.array(...) })
    }
});
```

**NakÅ‚ad:** 1 tydzieÅ„

---

#### Function Calling
**Problem:** Brak natywnego wsparcia dla tool/function calling.

**Proponowane API:**
```typescript
const response = await provider.chat(messages, {
    tools: [{
        type: "function",
        function: {
            name: "extract_event",
            parameters: { type: "object", properties: {...} }
        }
    }]
});
```

**NakÅ‚ad:** 2 tygodnie

---

## âœ… ZAKOÅƒCZONE (DONE)

### Krytyczne (P0)
- [x] **WebGPU Backend** â€” Full WebGPU acceleration support (10-50x speedup)
- [x] **countTokens()** â€” `provider.countTokens(text)`
- [x] **getContextWindow()** â€” `provider.getContextWindow()`
- [x] **Interface Consistency** â€” `ILLMModel` z `countTokens` i `getContextWindow`
- [x] **Spin-Lock Removal** â€” Promise-based `loadingPromise` we wszystkich modelach
- [x] **ModelManager Concurrency** â€” Race condition fix z deferred promise

### Wysokie (P1)
- [x] **AbortSignal Support** â€” `signal?: AbortSignal` w `ChatOptions`

### Åšrednie (P2)
- [x] **Adaptery Integracji** â€” LangChain (`@lxrt/langchain`), Vercel AI SDK (`@lxrt/vercel-ai`), Stagehand (`@lxrt/stagehand`)
- [x] **CLI ZarzÄ…dzania Modelami** â€” `lxrt pull`/`list`/`remove`
- [x] **VectorizationService Enhancements** â€” PDF (`pdf-parse`), DOCX (`mammoth`), Smart TextSplitter
- [x] **Logger Cleanup** â€” LogBus integration
- [x] **Fix Path Aliases** â€” `tsc-alias` w build pipeline
- [x] **Fix ONNX Conflict** â€” UsuniÄ™to bezpoÅ›redniÄ… zaleÅ¼noÅ›Ä‡
- [x] **Typy EventÃ³w** â€” `ProgressEvent`, `ReadyEvent` wyeksportowane
- [x] **Docs Streaming** â€” Dokumentacja `provider.stream()`
- [x] **Model Registry & Types** â€” Type-safe model selection
- [x] **Robust Integration Testing** â€” Golden datasets, semantic assertions
- [x] **Test Quality Review** â€” 3-tier architecture, fixtures
- [x] **Stagehand Interface** â€” `StagehandAdapter` z OpenAI-compatible API
- [x] **JSDOM Refactor** â€” Dynamic `await import('jsdom')`
- [x] **Unit Tests** â€” STT, TTS, OCR model tests
- [x] **Integration Tests** â€” `concurrent-load.test.ts`, `abort-signal.test.ts`
- [x] **Job Cancellation w Hooks** â€” AbortController w React/Vue

### Niskie (P3)
- [x] **Model Persistence Test** â€” `model-persistence.test.ts`
- [x] **LogBus** â€” `src/core/logging/LogBus.ts` z subscribe()
- [x] **ErrorPattern Enum** â€” 10 patternÃ³w + `LxrtError` base class
- [x] **BaseModel implements IModel**
- [x] **StagehandAdapter typed** â€” UsuniÄ™to `any`
- [x] **Refactor Error to ModelNotLoadedError**
- [x] **Unify Error Strings** â€” Error message constants
- [x] **GitHub Actions CI** â€” `.github/workflows/ci.yml`

### Auto-Tuning System (Fazy 0-5)
- [x] **Faza 0:** Model Presets (`chat-light`, `embedding-quality`)
- [x] **Faza 1:** Model Selection (auto-wybÃ³r na podstawie RAM, GPU)
- [x] **Faza 2:** DType Selection (auto kwantyzacja fp16/q8/q4)
- [x] **Faza 3:** Performance Mode (fast/balanced/quality)
- [x] **Faza 4:** WASM Threads (thread count optimization)
- [x] **Faza 5:** Context/Tokens Limits (OOM prevention)

---

## ðŸ“Š Podsumowanie

| Kategoria | Do zrobienia | ZakoÅ„czone |
|-----------|--------------|------------|
| ðŸ”´ Krytyczne | 0 | 6 |
| ðŸŸ¡ Wysokie | 3 | 1 |
| ðŸŸ¢ Åšrednie | 0 | 18 |
| ðŸ”µ Niskie | 0 | 8 |
| **Razem** | **3** | **33** |
